source = "epoch"

[splits.rec06pnAkLOr2t2mp]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.875
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.75
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.8125
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5625
"mistral/open-mistral-nemo-2407" = 0.75
"anthropic/claude-3-5-sonnet-20240620" = 0.8125
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.6875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.875
"google/gemini-1.0-pro-001" = 0.375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.375
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.6875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.5625
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.6875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.rec0Arme2jcXQZnAW]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.3125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.625
"mistral/mistral-small-2501" = 0.375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.625
"openai/o1-preview-2024-09-12" = 0.625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.3125
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 0.6875
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.3125
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.6875
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.5
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.75
"grok/grok-2-1212" = 0.625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.6875

[splits.rec0wZvZgiz320KRs]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.4375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.75
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.875
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.6875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.875
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.5625
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.6875
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.75
"anthropic/claude-3-opus-20240229" = 0.8125
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.875

[splits.rec0yTRmO1o1xCA6H]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.5
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.1875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.rec1zl5LvaatzGhFt]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.5
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.9375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.8125
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.5625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.875
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.75
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.6875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.rec260hNUCEj109Dj]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.75
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.4375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.8125
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.625
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.75
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.4375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.875

[splits.rec2UlKqC6RFHdcro]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.8125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.6875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.6875
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 0.8125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.rec2ZTsqazBZ3LTWZ]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.4375
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.25
"openai/gpt-4-0613" = 0.625
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.9375
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.4375
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.5
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 0.25
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.75
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.6875
"openai/gpt-4-0125-preview" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.3125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 1.0
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.rec2fsnzUuvNtUYK8]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.6875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.625
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.125
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.25
"openai/o4-mini-2025-04-16" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.625
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.75
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.625
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.25
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.4375
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.75
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.75
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.8125
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.3125
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.3125
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.rec4JrWy7Il8ho5vk]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.5
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.75
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.625
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.4375
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.5625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 0.1875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.8125
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.8125
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.rec4L69T0Y1AS4AFS]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 1.0
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.4375
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.875
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.6875
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.375
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.6875
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.875
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.8125
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.rec4UqStf9WUVif1f]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.75
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5625
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 0.6875
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.625
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.8125
"google/gemini-1.5-pro-001" = 0.5
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.1875

[splits.rec4r4KWNLrT7g2kR]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 0.25
"openai/o4-mini-2025-04-16" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5
"anthropic/claude-2.1" = 0.8125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.9375
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 0.5
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.375
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.75
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.6875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.6875
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.9375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 0.625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.5625
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.3125
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.625
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.375
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.1875

[splits.rec527dNeEtWJrYNl]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.6875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 1.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.625
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.8125
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 1.0
"mistral/open-mistral-nemo-2407" = 1.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 1.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.375
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 1.0
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.75
"mistral/open-mixtral-8x7b" = 0.8125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.5
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 1.0
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.9375
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.875
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.4375
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.875
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.625
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.75

[splits.rec5eA17Qr1ucNLUf]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.5625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.875
"anthropic/claude-3-5-sonnet-20240620" = 0.875
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.8125
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.9375
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5625
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.3125
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.6875
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.75
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.8125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.rec5rjeLsEq5Fg7Oj]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.375
"openai/o4-mini-2025-04-16" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.5
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.5
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.375
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5

[splits.rec7C06XOB2h298ue]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.6875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.8125
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.5
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.5625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.9375
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.75
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.5
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.375
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.875
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 0.75
"sagemaker/google/gemma-2-9b-it" = 0.75
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.625
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5625
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.9375
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.rec7qmSnbud4FHSqL]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5625
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.8125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.5625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.4375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.5
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.375
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.1875
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.6875

[splits.rec8nshandHARTkrg]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.5
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.75
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.375
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.125
"openai/gpt-3.5-turbo-1106" = 0.5625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.8125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 1.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.8125
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.5
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.875
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.rec8y3ZrBOcLgNEkE]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 1.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.8125
"anthropic/claude-2.1" = 0.9375
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.8125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.875
"mistral/open-mistral-nemo-2407" = 1.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.9375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 0.75
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.5625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.8125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.875
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 1.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 1.0
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.rec9GugrngvsQR99A]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.8125
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 0.75
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.375
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.25
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.5
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.4375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.75
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.1875

[splits.rec9ubQihAh6g9bft]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.25
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 1.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.25
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.625
"google/gemini-1.5-flash-002" = 0.5625
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.75
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.375
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recA1i5ZAh0Uzclxp]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.3125
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.625
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.875

[splits.recAAJoHMW45Lv5je]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.375
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.5625
"openai/o1-preview-2024-09-12" = 0.625
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.625
"anthropic/claude-3-5-sonnet-20241022" = 0.625
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 0.5625
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.5625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recBGxVySx1pkrO1i]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.375
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.1875
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.75
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.375
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.375
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.recBXlqrZUCR897It]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.375
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 0.375
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.125
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recBtVK8rBVtIlXDq]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.8125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.8125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.75
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.4375
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.8125
"google/gemini-1.0-pro-001" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.8125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.375
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.8125
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.6875
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recCJJOeBGERaHYax]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 0.625
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.6875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.8125
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.375
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.375
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.625
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.375
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recD8oX1KevFbl7bL]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.375
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.1875
"mistral/open-mixtral-8x7b" = 0.625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.5625
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.3125
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.375
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recDDxpS9s8cwkqfq]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.625
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.5
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.875
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.5
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.125
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.625
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.8125
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 0.625
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.4375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.6875
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 0.75
"anthropic/claude-3-opus-20240229" = 0.75
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5625

[splits.recDj2Y2BbtV02Wv5]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.3125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.125
"openai/o4-mini-2025-04-16" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.4375
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.125
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.5
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.625
"google/gemini-1.5-flash-001" = 0.75
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recDytVnNYZe2HuUU]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.75
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 0.5
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.4375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.75
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.625
"openai/o1-preview-2024-09-12" = 0.5
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.3125
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.5
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.75
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.625
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.9375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.875
"sagemaker/google/gemma-2-27b-it" = 0.5625
"openai/gpt-4o-mini-2024-07-18" = 0.75
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.375
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 0.5
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.3125

[splits.recEmTBhx2hgw6tPQ]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.6875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.375
"openai/o4-mini-2025-04-16" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.375
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.75
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.4375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 0.375
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.375
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recFaL6j8UMhutXrc]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 0.875
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.1875
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.25
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.75
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 1.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.375
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recG1ljJQcVy6CbSl]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.6875
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.4375
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.75
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.4375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.75
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.6875
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.75
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.3125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.4375
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recGFKDUd8qgz81Zl]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.6875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.6875
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5625
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5625
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.75
"mistral/open-mixtral-8x7b" = 0.4375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.8125
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.8125
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.375
"anthropic/claude-3-opus-20240229" = 0.375
"grok/grok-2-1212" = 0.8125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recGFNRVl1qBZGwyU]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.4375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recHVUd2DkoKfedJZ]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.875
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.625
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.5
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.375
"mistral/mistral-small-2501" = 0.625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.3125
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.75
"anthropic/claude-3-opus-20240229" = 0.4375
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.875

[splits.recI1ls9OXdxatHQn]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5625
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.4375
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.75
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.875
"google/gemini-1.0-pro-001" = 0.625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.875
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.9375
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.625
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recIDiDKKrN61Auyr]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.3125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.8125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.8125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.3125
"mistral/open-mixtral-8x7b" = 0.6875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.875
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recIIUynGGpsGEYuo]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.5625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5
"anthropic/claude-2.1" = 0.9375
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.75
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5625
"mistral/open-mistral-nemo-2407" = 0.5
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.5625
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.875
"google/gemini-1.0-pro-001" = 0.625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.75
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.5
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.9375
"google/gemini-1.5-pro-001" = 0.5
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recIMcQfaQNa6vzsT]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.375
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.5
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.9375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.6875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.8125
"anthropic/claude-3-opus-20240229" = 0.8125
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.75

[splits.recINSFEYLCyyd08m]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.625
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.375
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.75
"openai/gpt-3.5-turbo-1106" = 0.5625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 0.3125
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.5
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.75
"openai/gpt-4o-mini-2024-07-18" = 0.625
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.375
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recIOlKBsOeEcgkA1]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.625
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.8125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 0.75
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.5625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recIj8lR4tuDgrHou]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.375
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.125
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.4375
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.375
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.recIlghoOw5VbY4Zh]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.4375
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.3125
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.625
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.625
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recJJcOHhFeSaRpl4]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.75
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.6875
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 1.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.75
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.5625
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.8125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.5625
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.625
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.75
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.3125

[splits.recJZ3QEfRKjYw9a7]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.375
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.5
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 0.5625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.3125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recK9F5aqdaybl8bb]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.5
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.6875
"mistral/open-mistral-nemo-2407" = 0.5
"anthropic/claude-3-5-sonnet-20240620" = 0.5
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.125
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 1.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.5
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.75
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.375
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recKcjTwONILZqHAX]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5625
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5625
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.625
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.625
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.625
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.75
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.75
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.5625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.875
"openai/gpt-4o-mini-2024-07-18" = 0.75
"sagemaker/google/gemma-2-9b-it" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.6875
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5625
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.8125
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recKm6LNWykGapmCr]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.625
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.875
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recKv4hFyNpViUXnL]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.5
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.6875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.75
"google/gemini-1.5-pro-002" = 0.375
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.625
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recL9MFV5zmdlle5T]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.5625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.5625
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.5
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.5
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.375
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.6875
"grok/grok-2-1212" = 0.5625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recLAgwx9vbgB5EHk]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.5625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.3125
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.5
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.625
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 0.625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.8125
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.125
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.8125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.375
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recLSzwBUS3olCjhl]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.625
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.875
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.8125
"mistral/open-mistral-nemo-2407" = 0.75
"anthropic/claude-3-5-sonnet-20240620" = 0.6875
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.8125
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 0.1875
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.75
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.1875
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.9375
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.875
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.6875
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.6875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.6875
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recLrRirj7iXoB0rU]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.75
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.375
"anthropic/claude-3-haiku-20240307" = 0.5625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.9375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.8125
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 0.625
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.6875
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.6875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.875
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.75
"google/gemini-2.0-flash-001" = 0.75
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.6875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recN4DY9Q5V03glmQ]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.4375
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.75
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.375
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.8125
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.375
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.25
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recNAiPUKOulQbKVP]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.6875
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.9375
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.6875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.8125
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.5
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.375
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.9375
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.25
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.6875
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.625
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.9375
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recNFJjE5PPTqVJGv]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5625
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.8125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.8125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.9375
"google/gemini-1.5-pro-001" = 0.875
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.75

[splits.recNu3MXkvWUzHZr9]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.5625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.6875
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.375
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.5
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.8125
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.375
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.6875
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.75
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recNuT2oSnO86bxOx]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.75
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.9375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.6875
"anthropic/claude-2.1" = 0.9375
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5625
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.75
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.9375
"mistral/mistral-small-2501" = 0.5625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.3125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.875
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.125
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.875
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.75
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.625
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.8125
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recO3hvCWRGiG0odN]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.625
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5625
"openai/o3-2025-04-16" = 0.5
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.8125
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.6875
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.375
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.6875
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.25
"google/gemini-1.5-flash-002" = 0.5
"mistral/open-mixtral-8x7b" = 0.375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.5625
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 1.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.5
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.375
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recOYsaYs6RmtlTDy]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.875
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.4375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.3125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.9375
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.5
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.375
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.recOkA2zsy4GSMD9R]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.3125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.5
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.3125
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.5
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.625
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 0.375
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.625
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.3125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recOvqPKUtyy9ISA1]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5625
"anthropic/claude-2.1" = 0.4375
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.6875
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.75
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.4375
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.625
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.625
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.75
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.75
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.8125
"sagemaker/google/gemma-2-9b-it" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.6875
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.6875
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.625
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recPL4ZPpVYxgMu57]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.8125
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.75
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.9375
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.6875
"mistral/open-mistral-nemo-2407" = 0.75
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.6875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 1.0
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.6875
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 1.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.75
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.625
"openai/gpt-4o-mini-2024-07-18" = 0.75
"sagemaker/google/gemma-2-9b-it" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.9375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 1.0
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.recPSTGXK3P39yNYT]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.25
"anthropic/claude-3-haiku-20240307" = 0.4375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.75
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.625
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.75
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5625
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.4375
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.75
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.5625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.375
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.625
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recPzW1WqRnPs57D6]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.4375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.375
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.8125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5625
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.6875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.8125
"google/gemini-1.0-pro-001" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.6875
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.875
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.6875
"google/gemini-1.5-flash-001" = 0.75
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.8125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recQ8oxSY2aCwFRS8]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.75
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.625
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.8125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.4375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.6875
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.8125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.4375
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.5625
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.4375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.6875
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 0.75
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.75

[splits.recQiWOxhkXRz9NVE]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.5
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.3125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.25
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.75
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.4375
"openai/gpt-3.5-turbo-0125" = 0.375
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.75
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.4375
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.75

[splits.recRTiyaRymerDJ4y]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5625
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.75
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.625
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.375
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.8125

[splits.recRgabRzMaEoBRcM]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.125
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.375
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.3125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.3125
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.1875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.4375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 0.6875
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.3125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recS48OsU6kVadBPW]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.75
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.8125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.75
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.9375
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 1.0
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.9375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.5625
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.6875
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.625
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.9375
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recSBcGLPatKb3Ygu]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 0.8125
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.4375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.3125
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.75
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.4375
"openai/gpt-4-0125-preview" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.4375
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recTs7qzfJs6kfLUK]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.75
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.6875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.75
"anthropic/claude-2.1" = 0.5625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5625
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.625
"mistral/open-mistral-nemo-2407" = 0.5625
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.9375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.6875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.8125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.4375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.6875
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.6875
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.8125
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recUBgVlkKzcRPDdK]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.6875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 0.5
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.875
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.1875
"google/gemini-1.5-flash-002" = 0.3125
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.625
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.5
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.5625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.8125
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recUOePh79cp4T2Bg]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.6875
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recV1nqYQvpII94oC]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5625
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.8125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.625
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.6875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 1.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.25
"together/microsoft/WizardLM-2-8x22B" = 0.875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.75
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 1.0
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recVEXvhYxAhELVqB]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.5
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.5
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.4375
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.4375
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.875
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.25
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 1.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.75
"google/gemini-1.0-pro-001" = 0.75
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.4375
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.1875
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5625

[splits.recVvpD8miVjmmyfe]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.4375
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.25
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.625
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.8125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.1875
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.1875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.4375
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.3125
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recWPMm91mGDLXONm]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.5
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.4375
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.8125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.5625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.3125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.6875
"google/gemini-1.5-flash-8b-001" = 0.75
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.3125
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5625
"google/gemini-1.0-pro-001" = 0.375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.375
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.5
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.125
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.75
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.8125
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.75
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recWxGU8Q4YReJ1tb]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.6875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.875
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.375
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.375
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.3125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.25
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.5625
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.4375
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.5625
"mistral/mistral-large-2402" = 0.8125
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recWzUUYBN0NuXO2k]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.875
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.5
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.625
"openai/gpt-4o-mini-2024-07-18" = 0.5625
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.6875
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.75
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recXsuOHRBLcyenF2]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.875
"anthropic/claude-2.1" = 0.75
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 1.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 1.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.875
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.8125
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 1.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.375
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 0.875
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.6875
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 1.0
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recXvQ6gWAmyakrpD]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.25
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.375
"openai/gpt-3.5-turbo-1106" = 0.5625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.3125
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 0.6875
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.5
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.625
"anthropic/claude-3-5-sonnet-20241022" = 0.5
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.4375
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recYA3LPsCvF1fTMI]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recYOzCsevNz61Lyn]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.5
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.6875
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.375
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.875
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.8125
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.9375
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.5
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.3125
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.5
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.625
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.5
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.8125
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.125
"google/gemini-2.0-flash-001" = 0.25
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.4375
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.75
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recYt8xx80OTyDsL0]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.75
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.4375
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.6875
"mistral/open-mistral-nemo-2407" = 0.5
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.8125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.9375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.9375
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 1.0
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recZ13cwgDQf9jRd9]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.75
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.25
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5625
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.5625
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.625
"anthropic/claude-3-5-sonnet-20241022" = 0.75
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.6875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.recZSGUkn56v9kEp1]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.5
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.125
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.6875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.375
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.25
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.4375
"mistral/open-mistral-nemo-2407" = 0.75
"anthropic/claude-3-5-sonnet-20240620" = 0.125
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.625
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.25
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.75
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.8125
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.5
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.4375
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.6875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recZWeueB7lSPR6wN]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.25
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.5
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.5625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.75
"openai/gpt-3.5-turbo-1106" = 0.5625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.4375
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.75
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 0.6875
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.75
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.625
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.625
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recZbxrocrxh9YENH]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.375
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.125
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.4375
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.5
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.1875
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recZdZxsN0AxDx0pB]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.375
"openai/o1-preview-2024-09-12" = 0.625
"google/gemini-1.5-flash-002" = 0.1875
"mistral/open-mixtral-8x7b" = 0.625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.4375
"openai/gpt-3.5-turbo-0125" = 0.9375
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.3125
"google/gemini-1.0-pro-001" = 0.5
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.25
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.5
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.375
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.6875
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recZt4x514UQNnsgy]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.125
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.125
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.25
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.reca44yABeO2fx7UB]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 0.125
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.5625
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 0.25
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.75
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.3125

[splits.recaXdGn3FAIkxLGM]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.25
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.25
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.625
"anthropic/claude-3-5-sonnet-20241022" = 0.375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 0.6875
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.6875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recafnH3RRnMBXEb1]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.9375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.5625
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 1.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.375
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.8125
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.9375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.9375
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 1.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.5
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.625
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.6875
"google/gemini-1.0-pro-001" = 0.75
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.8125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.6875
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recakFKZioXUuldcd]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 0.25
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.4375
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.125
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.4375
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.4375
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 0.125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recb2M22zaD3tL6Qc]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.4375
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.4375
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.25
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.6875
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.625
"anthropic/claude-3-5-sonnet-20241022" = 0.75
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.25
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5625
"google/gemini-1.5-pro-001" = 0.4375
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recb4cGsC6BJUCU3V]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.5625
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.3125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.reccOKzFNmyqeJ6ry]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.4375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.9375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5625
"anthropic/claude-2.1" = 0.875
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 1.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 1.0
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.9375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.6875
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.75
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.6875
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.75
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.6875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.9375
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.6875
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.9375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.reccVFW11Elovnf8T]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 1.0
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.75
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.375
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.875
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.75
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 0.6875
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.6875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.75
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.375
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.8125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.6875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.8125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recclFbsjbaiVVnnV]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.75
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.3125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.6875
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.6875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.25
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.6875
"mistral/open-mixtral-8x7b" = 0.75
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.375
"mistral/ministral-8b-2410" = 0.625
"together/deepseek-ai/DeepSeek-V3" = 0.3125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.6875
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.4375
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.75
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.6875
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.375
"grok/grok-2-1212" = 0.3125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recdya6FuYraBU5Rh]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.4375
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.5
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.8125
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.6875
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.375
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.3125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.6875

[splits.receYQxnUBvxPcvbQ]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 0.75
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.8125
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.375
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.75
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.625
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.6875
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.875
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.75
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.receo3UUzRvWCqyfA]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.375
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.8125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.25
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.5
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recf6ayQmL1SxKbvW]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.75
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.9375
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.5625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.5
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.75
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.6875
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.recgI6tUQ7RLJRWGx]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.75
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.375
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.9375
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.875
"mistral/open-mistral-nemo-2407" = 0.875
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 1.0
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.625
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.6875
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.875
"google/gemini-1.0-pro-001" = 1.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.6875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.6875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.9375
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.9375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.875
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.75
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recgM7o1tcc7tP778]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.75
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.75
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.3125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.4375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.25
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.5625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 0.6875
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.5625
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.6875
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.375
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.4375
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.75

[splits.recgXxEgllSGEpELP]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.6875
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.25
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.4375
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.5
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.75
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.5
"anthropic/claude-3-5-sonnet-20241022" = 0.6875
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 0.75
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.3125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.rechKl68Uc6H7vU0N]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.375
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.5
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.75
"mistral/mistral-large-2402" = 0.8125
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.25
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.875
"openai/gpt-4-0125-preview" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.625
"openai/gpt-4o-2024-08-06" = 0.3125
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.rechgQucGlrnt8KRV]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5625
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5625
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.75
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.1875
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.6875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.4375
"grok/grok-2-1212" = 0.5625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5625

[splits.rechtUKxC6G67H7Pr]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.8125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.4375
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.6875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.625
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.6875
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.75
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.8125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 1.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.6875
"openai/gpt-4o-mini-2024-07-18" = 0.5625
"sagemaker/google/gemma-2-9b-it" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.625
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.4375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.625
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.6875
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.6875

[splits.recihePFulRgNKsIn]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.25
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.9375
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.125
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.75
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.625
"grok/grok-2-1212" = 0.25
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.reciuppdQde4FGX1z]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.6875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.4375
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.25
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.5
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.75
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.5625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recjJ54TXc04enRkZ]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.375
"grok/grok-3-mini-beta" = 0.25
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.8125
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.9375
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.5625
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.25
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.5
"openai/gpt-4o-2024-08-06" = 0.1875
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.5625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recjgMJaMxz4ESDF2]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.9375
"anthropic/claude-2.1" = 0.875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.75
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.75
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 1.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 1.0
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.reck1zKeCssmN82Ga]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.3125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5625
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.reck4G4xxv3YnpbtQ]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.375
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.9375
"openai/o3-2025-04-16" = 0.375
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.875
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.5
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.5
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.3125
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.625
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.125
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.625
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.1875

[splits.reckYqR92oJkqJXkE]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.8125
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.6875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.375
"openai/gpt-4-0125-preview" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.625
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.75
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.reckl6PkaEMWM50yZ]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.5625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.625
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.25
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.5
"anthropic/claude-3-5-sonnet-20240620" = 0.375
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.4375
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.625
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.625
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.5625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.6875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recl1UtgTVKishAq4]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.75
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.125
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.6875
"openai/o3-2025-04-16" = 0.25
"openai/o4-mini-2025-04-16" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.25
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.375
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.4375
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.4375
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.4375
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.4375
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 0.625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.4375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.4375
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.125
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.5
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.25
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recmI7EiLv72PxmYK]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.3125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.75
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.5
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 0.8125
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 0.1875
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.75
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.8125
"grok/grok-2-1212" = 0.8125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recmkvk6EFAmqyMxR]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.375
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.75
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recmwwQJnx7ll7bqL]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.8125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.8125
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.875
"mistral/open-mistral-nemo-2407" = 0.875
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.8125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.1875
"mistral/open-mixtral-8x7b" = 0.625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.9375
"sagemaker/google/gemma-2-27b-it" = 0.375
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.875
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recn3NhOhqAPLda16]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.25
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.1875
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.5
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.4375
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.625
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recnGEpF1srQpaqWq]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.375
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.4375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.125
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.3125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.4375
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.4375
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.6875
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recnTTKdBzfuoZ7w7]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.25
"anthropic/claude-3-haiku-20240307" = 0.5
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.5
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.6875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.6875
"mistral/open-mixtral-8x7b" = 0.375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.75
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.25
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.3125
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.9375
"grok/grok-2-1212" = 0.125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.recnawZPumSCLMVgp]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.5
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.625
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.3125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.25
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.5
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.375
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.3125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recnjViFrqlZNL3fY]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.75
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.6875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 0.5
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.125
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.5625
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.6875
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.5
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.reco8WSc71p8zAv4q]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.5
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.5
"openai/o4-mini-2025-04-16" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.8125
"mistral/open-mistral-7b" = 0.375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.5625
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recooG6bivTUJpDBz]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.375
"openai/o4-mini-2025-04-16" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.375
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.125
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 0.1875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.5
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.3125
"google/gemini-2.0-flash-001" = 0.1875
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.125
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.125
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recoy9ZLBsc7HIRBy]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.3125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.75
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.1875
"mistral/mistral-small-2501" = 0.625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.75
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.375
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.5
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.375
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.4375
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recpJmTOXx6T48nDJ]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.3125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5625
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.4375
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.6875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.625
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.75
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5625
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.875
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.8125
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.75
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.375
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.4375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.875
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.5
"openai/gpt-4o-mini-2024-07-18" = 0.8125
"sagemaker/google/gemma-2-9b-it" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.8125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.recpki12iG9RUGrz9]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.6875
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5625
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.375
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.6875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.6875
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.625
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.4375
"google/gemini-2.5-flash-preview-05-20" = 0.375
"anthropic/claude-2.0" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.8125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.625
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.6875
"openai/gpt-4o-mini-2024-07-18" = 0.5625
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.875
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.4375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.5625
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.8125
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.8125

[splits.recqFDvYKKRmbnoUb]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.5625
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.25
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.375
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.375
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.1875
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recqGD3fxPCI59vPQ]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.8125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.4375
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.125
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.4375
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.5625
"openai/o1-preview-2024-09-12" = 0.625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.5
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.9375
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.1875
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recqLRu4BcJvlSANc]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 1.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 1.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 1.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 0.875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recr3VHM4zYf6dMFY]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 0.125
"anthropic/claude-3-haiku-20240307" = 0.875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.8125
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.4375
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.4375
"openai/gpt-3.5-turbo-1106" = 1.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.25
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 1.0
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 1.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.75
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 0.8125
"sagemaker/google/gemma-2-9b-it" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0625
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 1.0
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recrHBEJJoDTV05JR]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.125
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.6875
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.5
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5625
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.6875
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.4375
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.25
"openai/o1-preview-2024-09-12" = 0.3125
"google/gemini-1.5-flash-002" = 0.4375
"mistral/open-mixtral-8x7b" = 0.4375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.4375
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.3125
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.5
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.3125

[splits.recrNbtgTNoabJJi6]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 0.375
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.625
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.25
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.1875
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.1875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.5625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.3125
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.recrs0kUo7Ua1xhKO]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5
"anthropic/claude-2.1" = 0.5
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.8125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.875
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.75
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.625
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.875
"sagemaker/google/gemma-2-9b-it" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.9375
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recs3PLPUEMiqg4P8]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.375
"grok/grok-3-mini-beta" = 0.25
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.125
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.rect4iLrSfUwkNTno]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.4375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 0.6875
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.4375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.6875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.625
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.4375
"sagemaker/microsoft/phi-4" = 0.1875
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.5625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.3125
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.rectXfsCM1dj4Kv2c]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.6875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.25
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.375
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.4375
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.75
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.125
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.375
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.5
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.4375
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.3125
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 0.1875
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.75
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.3125
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.625
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.75

[splits.rectlyG9pCAAuWhoB]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.3125
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 0.5
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.6875
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 0.25
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.375
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.4375
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.5
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.9375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.5
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 1.0
"google/gemini-1.5-flash-001" = 0.5625
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.4375
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recuYEkVjdVUwA3c0]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.375
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.8125
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.375
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.625
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.4375
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.4375
"openai/gpt-4o-2024-08-06" = 0.75
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recuyeuT5rQ6qDt8F]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.6875
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.25
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.5625
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.1875
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.6875
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.75
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5625

[splits.recv7GsQg3f0fvB1f]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.75
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.4375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.8125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.75
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.4375
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.875
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.125
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.9375
"google/gemini-1.0-pro-001" = 0.75
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 1.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.625
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.75
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.6875
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recvZlMbpPz0yLDle]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.4375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.75
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.6875
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.75
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.4375
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.25
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.5625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.6875
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.5
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.4375
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.5625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.75
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 0.4375
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.6875
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.9375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5

[splits.recvlnu8BuLmXZhSX]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.4375
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.4375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.875
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.375
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.8125
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.75
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.6875
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.5
"anthropic/claude-3-opus-20240229" = 0.625
"grok/grok-2-1212" = 0.8125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.6875

[splits.recw4rROcnHKNZhtK]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.6875
"anthropic/claude-2.1" = 0.1875
"mistral/open-mistral-7b" = 0.4375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.875
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.875
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 1.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.625
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recxTy0x7M6T9ikc0]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.875
"anthropic/claude-3-5-sonnet-20240620" = 0.4375
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.6875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.25
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.125
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.9375
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.9375
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.3125

[splits.recxsX66ktJ1Lwt4f]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.25
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.6875
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.5625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.5
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.875
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recyPffUDqC2k7ZZO]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.6875
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.3125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5625
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.625
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.5
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.75
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5625
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.8125
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.6875
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.375
"anthropic/claude-2.0" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.6875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.625
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.875

[splits.recyl3usDqb7ruXJx]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0625
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.6875
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.875
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.75
"google/gemini-1.5-pro-002" = 0.4375
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.375
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 0.5
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.1875
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recypVp2NmPlBKVTp]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 1.0
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 1.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 1.0
"mistral/open-mistral-nemo-2407" = 1.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 1.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.9375
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 1.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.9375
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.9375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 1.0
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.9375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.reczQ4I0VpENdMtIj]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.75
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.875
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.375
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.625
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.25
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.9375
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.9375
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.375
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.125
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 1.0
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.5625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.6875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.375
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.375
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.reczUoM8JsxU6pYxr]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5625
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.25
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5625
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.5625
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5625
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.6875
"mistral/mistral-small-2501" = 0.5625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.625
"openai/o1-preview-2024-09-12" = 0.4375
"google/gemini-1.5-flash-002" = 0.75
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.6875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.6875
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.5
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 0.75
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.5625
"openai/gpt-4o-mini-2024-07-18" = 0.8125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.25
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.375
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.375
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.reczjcMtrB1YGS2fO]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.5
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.5625
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.3125
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.5
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.5
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.5625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.reczzzihL7btBH7RO]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.8125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.9375
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.6875
"anthropic/claude-2.1" = 0.8125
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.875
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.875
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.875
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 0.75
"google/gemini-1.5-pro-002" = 0.6875
"openai/o1-preview-2024-09-12" = 0.1875
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.9375
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.6875
"together/deepseek-ai/DeepSeek-V3" = 0.4375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 0.375
"mistral/mistral-large-2407" = 0.75
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.75
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.875
"mistral/mistral-large-2402" = 0.5
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.1875
"openai/gpt-4-0125-preview" = 0.6875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.625
"google/gemini-1.5-pro-001" = 0.8125
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.6875
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.rec0VuKUjt1SZ7NYv]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.9375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.625
"anthropic/claude-2.1" = 0.9375
"mistral/open-mistral-7b" = 0.375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.3125
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.9375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.6875
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.6875
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.5
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.8125
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.9375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.rec1oj2DveQWl9Rpw]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.1875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 0.25
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.1875
"anthropic/claude-3-5-haiku-20241022" = 0.5
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.25
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.125
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.5
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.3125
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.rec32C1ZEapBnCC0E]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.3125
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.5625
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.25
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.75
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 0.25
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.6875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.3125
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.375
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.625
"anthropic/claude-3-5-sonnet-20241022" = 0.9375
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.1875
"anthropic/claude-3-opus-20240229" = 0.4375
"grok/grok-2-1212" = 0.25
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.1875

[splits.rec47oNPXudlTIk4y]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.75
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.375
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.5625
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.75
"openai/o3-mini-2025-01-31" = 0.625
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 1.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5625
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.3125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.75
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 1.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.625
"google/gemini-1.0-pro-001" = 0.375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 0.125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.75
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.4375
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.8125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.6875
"google/gemini-1.5-flash-001" = 0.5
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.875
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.75
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.rec6sE2CRtD4drtHg]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.9375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.625
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.4375
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.75
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.6875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.375
"google/gemini-1.5-flash-002" = 0.9375
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.625
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 0.5625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 0.6875
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.6875
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 0.875
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.8125
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.375
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.6875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.6875
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.8125

[splits.rec9W28HgpEUeUN8k]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.125
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.5625
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.6875
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.5625
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.6875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.75
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.5
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.375
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.6875
"google/gemini-2.0-flash-001" = 0.375
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.625
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.25
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recAYkd96NNuNl1Ei]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.0
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.5
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.3125
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recBhnXrUyTJ6WHIR]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.75
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.5
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.8125
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.5625
"anthropic/claude-3-5-sonnet-20240620" = 0.9375
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.625
"mistral/mistral-small-2501" = 0.375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.8125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.5
"openai/gpt-4o-2024-05-13" = 0.5625
"google/gemini-1.5-flash-8b-001" = 0.75
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.375
"google/gemini-1.5-flash-002" = 0.5625
"mistral/open-mixtral-8x7b" = 0.75
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.9375
"openai/gpt-3.5-turbo-0125" = 0.6875
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.625
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.625
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.4375
"sagemaker/google/gemma-2-9b-it" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.6875
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.6875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.5
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.875
"anthropic/claude-3-opus-20240229" = 0.3125
"grok/grok-2-1212" = 0.6875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recE2ihVfqEK4R9d0]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.75
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.9375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.75
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.75
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.5625
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.375
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 0.6875
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.9375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.4375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.25
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 0.8125
"mistral/mistral-large-2411" = 0.25
"together/databricks/dbrx-instruct" = 0.9375
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.6875
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.625
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.5625
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.1875
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.6875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recGee5m84dg5FZkc]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.9375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.5625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.375
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.75
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.6875
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.375
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.5625
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.625
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.6875
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 0.1875
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 0.8125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.875
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.75
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.125
"openai/gpt-4-0125-preview" = 0.8125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.4375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recINGR1z01Fh1Z3A]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.4375
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.6875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.6875
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.375
"mistral/open-mistral-nemo-2407" = 0.75
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.75
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.625
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.875
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.5625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 1.0
"google/gemini-1.0-pro-001" = 0.5
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.6875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.9375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 0.6875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.875
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.75
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.875
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.75
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.75
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.6875
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.875

[splits.recJpyGtGIsxulevT]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.5625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.375
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.1875
"mistral/open-mistral-nemo-2407" = 0.5625
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.4375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5625
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.625
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.9375
"openai/o1-preview-2024-09-12" = 0.5625
"google/gemini-1.5-flash-002" = 0.625
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.1875
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.75
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.75
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.8125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.3125
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.625
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.625
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.6875
"google/gemini-1.5-pro-001" = 0.5
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5625

[splits.recLB0EkQ54bYVhnd]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.125
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.25
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 0.875
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.1875
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.3125
"mistral/mistral-small-2501" = 0.3125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.375
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.375
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.125
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.375
"anthropic/claude-2.0" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.125
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.125
"alibaba/qwq-plus" = 0.625
"mistral/ministral-8b-2410" = 0.6875
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.125
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.9375
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.625
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.1875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recMicVBcqy1xM1jq]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.125
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.0
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.375
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.125
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.3125
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0625
"google/gemini-1.5-flash-001" = 0.25
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.125
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recPIzpnuYpB4yvmp]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.75
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5625
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.6875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.375
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.75
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.4375
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.4375
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.1875
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.875
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.4375
"google/gemini-2.5-flash-preview-05-20" = 0.75
"anthropic/claude-2.0" = 0.125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.875
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.8125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.75
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 0.625
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.1875
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.1875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.1875
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5
"openai/gpt-4-0125-preview" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.3125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.3125
"google/gemini-1.5-pro-001" = 0.25
"openai/gpt-4o-2024-08-06" = 0.5625
"anthropic/claude-3-opus-20240229" = 0.625
"grok/grok-2-1212" = 0.6875
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recRZjaElf8ft7xTq]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.5
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.375
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.8125
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.3125
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.25
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0625
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.1875
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.1875
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recReg13iV2HwJTaA]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.375
"openai/gpt-4-turbo-2024-04-09" = 0.875
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.1875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.625
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.6875
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.625
"anthropic/claude-3-5-haiku-20241022" = 0.875
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.8125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 1.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.875
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.9375
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 1.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.875
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.8125
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.5625
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.8125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 0.625
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.625
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.8125
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.875
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.875
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recRhwQwHijW0gCLo]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.1875
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.25
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.125
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.0
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.5625
"anthropic/claude-3-5-sonnet-20240620" = 0.5
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.125
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.75
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.375
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recUc29lMDBEvurYo]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.6875
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.5
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.4375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.5
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 0.375
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.8125
"mistral/mistral-small-2501" = 0.125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.5625
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 0.25
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 0.25
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.25
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.375
"anthropic/claude-3-5-sonnet-20241022" = 0.625
"alibaba/qwen-max-2025-01-25" = 0.25
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.5
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.625
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.375
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.5625
"mistral/mistral-large-2402" = 0.5625
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.3125
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.25
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.5625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recVE8cUNHpHZIAvL]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.25
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 0.375
"anthropic/claude-3-haiku-20240307" = 0.4375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.25
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.5625
"anthropic/claude-3-5-sonnet-20240620" = 0.0
"openai/gpt-3.5-turbo-1106" = 0.4375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.25
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0625
"openai/o1-preview-2024-09-12" = 0.75
"google/gemini-1.5-flash-002" = 0.0625
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.125
"openai/gpt-3.5-turbo-0125" = 0.125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.625
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.0
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.625
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.25
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.75
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.0625
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recWXwn9v4IG9ZrM6]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.5625
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 1.0
"anthropic/claude-2.1" = 1.0
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.875
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.9375
"mistral/open-mistral-nemo-2407" = 0.9375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 1.0
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.6875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 1.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.9375
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.9375
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 1.0
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 1.0
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 0.125
"openai/gpt-4.1-nano-2025-04-14" = 1.0
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.4375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recXsYa3i2UhGF5fe]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.625
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.1875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.1875
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.75
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.3125
"anthropic/claude-3-5-sonnet-20240620" = 0.75
"openai/gpt-3.5-turbo-1106" = 0.3125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.1875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.375
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0625
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.125
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.375
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.4375
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.3125
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.1875
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.25
"sagemaker/microsoft/phi-4" = 0.1875
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.25
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.3125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.375
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.5
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.875
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.1875
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.375
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.4375
"mistral/mistral-small-2503" = 0.5
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.25
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.875
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 0.4375
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.5625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.recYCMJWH7IpcdqwE]
"anthropic/claude-sonnet-4-20250514" = 0.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.375
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.5
"anthropic/claude-3-haiku-20240307" = 0.4375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.75
"mistral/open-mistral-7b" = 0.4375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.1875
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.3125
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.75
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.0625
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.75
"mistral/mistral-small-2501" = 0.5625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.125
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.125
"openai/gpt-4o-2024-05-13" = 0.1875
"google/gemini-1.5-flash-8b-001" = 0.5
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.0625
"google/gemini-1.5-flash-002" = 0.1875
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.625
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.25
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.125
"mistral/ministral-8b-2410" = 0.25
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.125
"google/gemini-2.0-flash-001" = 0.0625
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.625
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.5625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 0.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.125
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.125
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.375
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.0
"openai/gpt-4o-2024-08-06" = 0.6875
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recatj4YXzbOaq3Ar]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.8125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 0.75
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.9375
"anthropic/claude-2.1" = 0.625
"mistral/open-mistral-7b" = 0.375
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.6875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.9375
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.9375
"mistral/open-mistral-nemo-2407" = 1.0
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.9375
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.8125
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 1.0
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 1.0
"alibaba/qwen-turbo-2024-11-01" = 0.75
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.875
"openai/gpt-4-1106-preview" = 0.9375
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.3125
"google/gemini-1.0-pro-001" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.8125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.8125
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 1.0
"mistral/mistral-large-2402" = 1.0
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.8125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 1.0
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0625
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.4375

[splits.recb80OwMgNnceA9t]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.0625
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.3125
"grok/grok-3-beta" = 0.0
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.625
"openai/o3-2025-04-16" = 0.25
"openai/o4-mini-2025-04-16" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.25
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.4375
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.625
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.125
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.6875
"openai/gpt-3.5-turbo-1106" = 0.125
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 0.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.5
"mistral/open-mixtral-8x7b" = 0.125
"google/gemini-2.5-flash-preview-05-20" = 0.25
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.25
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0625
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.75
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.1875
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.875
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 0.5
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.8125
"openai/gpt-4o-mini-2024-07-18" = 0.375
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.25
"mistral/mistral-small-2503" = 0.125
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.1875
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.25
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.5625
"openai/gpt-4-0125-preview" = 0.625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0625
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.reccVBrYdwsB84fGy]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.0
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.1875
"grok/grok-3-beta" = 0.5
"grok/grok-3-mini-beta" = 0.625
"anthropic/claude-3-haiku-20240307" = 0.125
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.3125
"openai/o3-2025-04-16" = 0.125
"openai/o4-mini-2025-04-16" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.625
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 0.125
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.5
"openai/o1-2024-12-17" = 0.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.3125
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.125
"openai/gpt-3.5-turbo-1106" = 0.5
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.3125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.1875
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.25
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.1875
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.0
"openai/gpt-4o-2024-05-13" = 0.0625
"google/gemini-1.5-flash-8b-001" = 0.125
"openai/gpt-4-1106-preview" = 0.4375
"openai/o1-mini-2024-09-12" = 0.125
"google/gemini-1.5-pro-002" = 0.0
"openai/o1-preview-2024-09-12" = 0.375
"google/gemini-1.5-flash-002" = 0.1875
"mistral/open-mixtral-8x7b" = 0.4375
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.75
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 0.0
"openai/gpt-3.5-turbo-0125" = 0.6875
"alibaba/qwen-plus-2025-01-25" = 0.625
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.25
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.3125
"alibaba/qwq-plus" = 0.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 0.0625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.375
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.75
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 0.25
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.0625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.125
"google/gemini-1.5-flash-001" = 0.375
"mistral/mistral-large-2402" = 0.25
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.375
"openai/gpt-4-0125-preview" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.1875
"google/gemini-1.5-pro-001" = 0.3125
"openai/gpt-4o-2024-08-06" = 0.125
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.5

[splits.recfTlTMjZBuOducT]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.25
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0625
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.6875
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.3125
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.3125
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.25
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0625
"google/gemma-3-27b-it" = 0.625
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.4375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.5
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.25
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.25
"google/gemini-1.5-pro-002" = 0.3125
"openai/o1-preview-2024-09-12" = 0.0
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.0625
"alibaba/qwq-plus" = 0.375
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 0.875
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.375
"sagemaker/01-ai/Yi-34B-Chat" = 0.4375
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.25
"anthropic/claude-3-5-sonnet-20241022" = 0.375
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 0.5
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.4375
"google/gemini-1.5-flash-001" = 0.4375
"mistral/mistral-large-2402" = 0.0625
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.4375
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.125
"openai/gpt-4o-2024-08-06" = 0.375
"anthropic/claude-3-opus-20240229" = 0.25
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.25
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.recgC4GJ8wUemlUQD]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.9375
"openai/gpt-4-turbo-2024-04-09" = 0.125
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.4375
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.0
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.625
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0625
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.5
"openai/gpt-4-0613" = 0.25
"anthropic/claude-3-5-haiku-20241022" = 1.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.5
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.25
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.8125
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.0625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.75
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.5
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.75
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.5
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.3125
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.875
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.3125
"alibaba/qwen-max-2025-01-25" = 0.625
"mistral/mistral-large-2407" = 0.0625
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.125
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.6875
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.0625
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 0.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25

[splits.recixxJmdux0d8LZQ]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 1.0
"openai/gpt-4-turbo-2024-04-09" = 0.5
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.5
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.625
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.9375
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.75
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.0
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.25
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0
"mistral/open-mistral-nemo-2407" = 0.0
"anthropic/claude-3-5-sonnet-20240620" = 0.5625
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.8125
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.875
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.3125
"google/gemini-1.5-flash-8b-001" = 0.75
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 1.0
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.875
"mistral/ministral-8b-2410" = 0.4375
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.25
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.5
"anthropic/claude-3-5-sonnet-20241022" = 0.375
"alibaba/qwen-max-2025-01-25" = 0.875
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 1.0
"openai/gpt-4o-mini-2024-07-18" = 0.125
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.875
"openai/gpt-4.1-nano-2025-04-14" = 0.75
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.875
"fireworks/accounts/fireworks/models/deepseek-r1" = 0.75
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.25
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.0625
"grok/grok-2-1212" = 0.75
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.875
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.reckEnrOPFT9Ru7tW]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.375
"anthropic/claude-3-sonnet-20240229" = 0.875
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.8125
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.1875
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.9375
"grok/grok-3-beta" = 0.375
"grok/grok-3-mini-beta" = 0.75
"anthropic/claude-3-haiku-20240307" = 1.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.25
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.5
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.625
"anthropic/claude-3-5-sonnet-20240620" = 0.375
"openai/gpt-3.5-turbo-1106" = 0.9375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.875
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.75
"mistral/mistral-small-2501" = 0.875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.5
"alibaba/qwen-turbo-2024-11-01" = 0.625
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.875
"openai/gpt-4o-2024-05-13" = 0.375
"google/gemini-1.5-flash-8b-001" = 0.375
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 0.625
"openai/o1-preview-2024-09-12" = 0.25
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.3125
"sagemaker/microsoft/phi-4" = 0.5625
"openai/gpt-3.5-turbo-0125" = 0.75
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.4375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.375
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.375
"together/deepseek-ai/DeepSeek-V3" = 0.625
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.125
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.6875
"alibaba/qwen-max-2025-01-25" = 0.75
"mistral/mistral-large-2407" = 0.9375
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.75
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.875
"openai/gpt-4o-mini-2024-07-18" = 0.5
"sagemaker/google/gemma-2-9b-it" = 1.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.6875
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.75
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.4375
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.375
"google/gemini-1.5-flash-001" = 0.5625
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.5625
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.4375
"openai/gpt-4-0125-preview" = 0.4375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.5
"openai/gpt-4o-2024-08-06" = 0.4375
"anthropic/claude-3-opus-20240229" = 0.625
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.9375

[splits.recoiTJPGUmzAkief]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.5
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.875
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.875
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.5
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.25
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.9375
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.125
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.0625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.875
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.5
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.5
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.8125
"alibaba/qwen-turbo-2024-11-01" = 1.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 1.0
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.25
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.0
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.0
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.4375
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.9375
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.3125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.5625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.75
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 1.0
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 1.0
"sagemaker/google/gemma-2-27b-it" = 0.875
"openai/gpt-4o-mini-2024-07-18" = 0.9375
"sagemaker/google/gemma-2-9b-it" = 0.9375
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.9375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.9375
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.5
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.6875
"mistral/mistral-large-2402" = 0.9375
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 0.9375
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.375
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 0.9375
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.8125

[splits.recwW1A85nfyQpReG]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.625
"anthropic/claude-3-sonnet-20240229" = 0.0
"openai/gpt-4-turbo-2024-04-09" = 0.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.0
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 0.0
"anthropic/claude-3-haiku-20240307" = 0.0
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.5
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.125
"anthropic/claude-3-7-sonnet-20250219" = 0.125
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.875
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.0625
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.0
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0625
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 0.75
"openai/gpt-4o-2024-05-13" = 0.0
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.0
"openai/o1-mini-2024-09-12" = 0.5
"google/gemini-1.5-pro-002" = 0.125
"openai/o1-preview-2024-09-12" = 0.5
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.0625
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 0.875
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 0.1875
"openai/gpt-3.5-turbo-0125" = 0.0625
"alibaba/qwen-plus-2025-01-25" = 0.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.0625
"google/gemini-1.0-pro-001" = 0.0
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.0
"together/microsoft/WizardLM-2-8x22B" = 0.1875
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0
"together/deepseek-ai/DeepSeek-V3" = 0.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0625
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.0
"alibaba/qwen-max-2025-01-25" = 0.0
"mistral/mistral-large-2407" = 0.0
"google/gemini-2.0-flash-001" = 0.125
"mistral/mistral-large-2411" = 0.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.0
"google/gemini-2.0-pro-exp-02-05" = 0.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.0
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.5
"openai/gpt-4o-2024-11-20" = 0.0625
"mistral/mistral-medium-2505" = 0.375
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.0625
"openai/gpt-4-0125-preview" = 0.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 0.0
"mistral/ministral-3b-2410" = 0.0625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0
"google/gemini-1.5-pro-001" = 0.5625
"openai/gpt-4o-2024-08-06" = 0.0
"anthropic/claude-3-opus-20240229" = 0.0
"grok/grok-2-1212" = 0.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.125

[splits.recwlwlcPvXVNPmvl]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.625
"openai/gpt-4-turbo-2024-04-09" = 0.75
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.25
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.8125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.1875
"anthropic/claude-2.1" = 0.8125
"mistral/open-mistral-7b" = 0.0625
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.5
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.875
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.25
"anthropic/claude-3-5-sonnet-20240620" = 0.875
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.75
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 1.0
"mistral/mistral-small-2501" = 0.8125
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.25
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.8125
"google/gemini-1.5-flash-8b-001" = 0.625
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.9375
"google/gemini-1.5-flash-002" = 0.6875
"mistral/open-mixtral-8x7b" = 0.1875
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.5625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.6875
"alibaba/qwen-plus-2025-01-25" = 0.875
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.375
"google/gemini-1.0-pro-001" = 0.25
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.5
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.875
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.875
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.75
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.1875
"openai/gpt-4o-mini-2024-07-18" = 0.25
"sagemaker/google/gemma-2-9b-it" = 0.1875
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.625
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.8125
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.3125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.75
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.75
"mistral/mistral-large-2402" = 0.6875
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.875
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.8125
"openai/gpt-4-0125-preview" = 1.0
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.5625
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5625
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 0.9375
"anthropic/claude-3-opus-20240229" = 0.9375
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.625

[splits.recyrk6XBVwugG5u8]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.25
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.0625
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.4375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.25
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.4375
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.0
"anthropic/claude-2.1" = 0.0625
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.375
"anthropic/claude-3-7-sonnet-20250219" = 0.875
"openai/gpt-4-0613" = 0.0
"anthropic/claude-3-5-haiku-20241022" = 0.375
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.75
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.0625
"mistral/open-mistral-nemo-2407" = 0.375
"anthropic/claude-3-5-sonnet-20240620" = 0.1875
"openai/gpt-3.5-turbo-1106" = 0.1875
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.25
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.0
"mistral/mistral-small-2501" = 0.1875
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.125
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.5
"google/gemini-1.5-flash-8b-001" = 0.25
"openai/gpt-4-1106-preview" = 0.0625
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 0.1875
"openai/o1-preview-2024-09-12" = 0.125
"google/gemini-1.5-flash-002" = 0.0
"mistral/open-mixtral-8x7b" = 0.3125
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.0625
"openai/gpt-3.5-turbo-0125" = 0.5
"alibaba/qwen-plus-2025-01-25" = 0.5
"google/gemini-2.0-flash-thinking-exp-01-21" = 0.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.1875
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.5
"together/microsoft/WizardLM-2-8x22B" = 0.25
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.5
"together/deepseek-ai/DeepSeek-V3" = 0.375
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 0.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0625
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 0.125
"alibaba/qwen-max-2025-01-25" = 0.125
"mistral/mistral-large-2407" = 0.4375
"google/gemini-2.0-flash-001" = 0.875
"mistral/mistral-large-2411" = 0.125
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.5625
"openai/gpt-4o-mini-2024-07-18" = 0.3125
"sagemaker/google/gemma-2-9b-it" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.3125
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 0.25
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.125
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.25
"google/gemini-1.5-flash-001" = 0.0625
"mistral/mistral-large-2402" = 0.3125
"openai/gpt-4.1-nano-2025-04-14" = 0.375
"openai/gpt-4o-2024-11-20" = 0.25
"mistral/mistral-medium-2505" = 0.125
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.125
"google/gemini-1.5-pro-001" = 0.0625
"openai/gpt-4o-2024-08-06" = 0.25
"anthropic/claude-3-opus-20240229" = 0.125
"grok/grok-2-1212" = 0.125
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.4375
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0

[splits.recywRj5a8EEjj2Ib]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 1.0
"anthropic/claude-3-sonnet-20240229" = 0.4375
"openai/gpt-4-turbo-2024-04-09" = 1.0
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 1.0
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.375
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 1.0
"grok/grok-3-beta" = 1.0
"grok/grok-3-mini-beta" = 0.875
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 1.0
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.375
"anthropic/claude-2.1" = 0.75
"mistral/open-mistral-7b" = 0.125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.875
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 1.0
"anthropic/claude-3-5-haiku-20241022" = 0.625
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.6875
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 1.0
"openai/gpt-3.5-turbo-1106" = 0.375
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.5
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 1.0
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.9375
"mistral/mistral-small-2501" = 0.9375
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 1.0
"alibaba/qwen-turbo-2024-11-01" = 0.875
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 1.0
"google/gemini-1.5-flash-8b-001" = 1.0
"openai/gpt-4-1106-preview" = 0.875
"openai/o1-mini-2024-09-12" = 1.0
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 1.0
"mistral/open-mixtral-8x7b" = 0.9375
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.1875
"sagemaker/microsoft/phi-4" = 1.0
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 1.0
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.3125
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.75
"together/microsoft/WizardLM-2-8x22B" = 1.0
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.125
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.1875
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.75
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 1.0
"anthropic/claude-3-5-sonnet-20241022" = 1.0
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.875
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 1.0
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.875
"openai/gpt-4o-mini-2024-07-18" = 0.625
"sagemaker/google/gemma-2-9b-it" = 0.5
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.875
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.25
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.5
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.5625
"google/gemini-1.5-flash-001" = 0.9375
"mistral/mistral-large-2402" = 0.875
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 1.0
"openai/gpt-4-0125-preview" = 0.9375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.4375
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.875
"google/gemini-1.5-pro-001" = 1.0
"openai/gpt-4o-2024-08-06" = 1.0
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 1.0

[splits.recz3MfYHPRhsEQkW]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.5
"anthropic/claude-3-sonnet-20240229" = 0.5625
"openai/gpt-4-turbo-2024-04-09" = 0.625
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.25
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.3125
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.125
"grok/grok-3-beta" = 0.75
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.0625
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 0.75
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.25
"mistral/open-mistral-7b" = 0.0
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.0625
"anthropic/claude-3-5-haiku-20241022" = 0.0
"openai/o3-mini-2025-01-31" = 0.875
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 0.625
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.4375
"anthropic/claude-3-5-sonnet-20240620" = 0.625
"openai/gpt-3.5-turbo-1106" = 0.625
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.0625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.0
"google/gemma-3-27b-it" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.25
"mistral/mistral-small-2501" = 0.5
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.0
"alibaba/qwen-turbo-2024-11-01" = 0.0
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.5625
"openai/o1-mini-2024-09-12" = 0.625
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 0.875
"google/gemini-1.5-flash-002" = 0.4375
"mistral/open-mixtral-8x7b" = 0.5
"google/gemini-2.5-flash-preview-05-20" = 0.125
"anthropic/claude-2.0" = 0.3125
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.375
"sagemaker/microsoft/phi-4" = 0.625
"openai/gpt-3.5-turbo-0125" = 0.25
"alibaba/qwen-plus-2025-01-25" = 0.125
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.75
"google/gemini-1.0-pro-001" = 0.375
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 0.125
"together/microsoft/WizardLM-2-8x22B" = 0.6875
"alibaba/qwq-plus" = 0.75
"mistral/ministral-8b-2410" = 0.5625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.0
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.0
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.0
"anthropic/claude-3-5-sonnet-20241022" = 0.1875
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.375
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.875
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.25
"openai/gpt-4o-mini-2024-07-18" = 0.0
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.25
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.125
"mistral/mistral-small-2503" = 1.0
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.1875
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 0.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.0
"google/gemini-1.5-flash-001" = 0.8125
"mistral/mistral-large-2402" = 0.875
"openai/gpt-4.1-nano-2025-04-14" = 0.0
"openai/gpt-4o-2024-11-20" = 1.0
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.9375
"openai/gpt-4-0125-preview" = 0.375
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.0
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.0625
"google/gemini-1.5-pro-001" = 0.9375
"openai/gpt-4o-2024-08-06" = 0.8125
"anthropic/claude-3-opus-20240229" = 1.0
"grok/grok-2-1212" = 1.0
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.3125
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.0625

[splits.reczkBiPPNrNN49Hp]
"anthropic/claude-sonnet-4-20250514" = 1.0
"openai/gpt-4.1-mini-2025-04-14" = 0.875
"anthropic/claude-3-sonnet-20240229" = 0.8125
"openai/gpt-4-turbo-2024-04-09" = 0.375
"hyperbolic/Qwen/Qwen2.5-72B-Instruct" = 0.6875
"sagemaker/deepseek-ai/deepseek-llm-67b-chat" = 0.25
"sagemaker/Qwen/Qwen2.5-32B-Instruct" = 0.8125
"grok/grok-3-beta" = 0.875
"grok/grok-3-mini-beta" = 1.0
"anthropic/claude-3-haiku-20240307" = 0.75
"sagemaker/Qwen/Qwen2-72B-Instruct" = 0.125
"openai/o3-2025-04-16" = 1.0
"openai/o4-mini-2025-04-16" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct" = 0.25
"anthropic/claude-2.1" = 0.125
"mistral/open-mistral-7b" = 0.3125
"sagemaker/Qwen/Qwen1.5-32B-Chat" = 0.0625
"anthropic/claude-3-7-sonnet-20250219" = 1.0
"openai/gpt-4-0613" = 0.125
"anthropic/claude-3-5-haiku-20241022" = 0.125
"openai/o3-mini-2025-01-31" = 1.0
"fireworks/accounts/fireworks/models/deepseek-v3-0324" = 1.0
"openai/o1-2024-12-17" = 1.0
"sagemaker/mistralai/Mixtral-8x7B-Instruct-v0.1" = 0.25
"mistral/open-mistral-nemo-2407" = 0.125
"anthropic/claude-3-5-sonnet-20240620" = 0.875
"openai/gpt-3.5-turbo-1106" = 0.25
"sagemaker/allenai/Llama-3.1-Tulu-3-70B-DPO" = 0.625
"sagemaker/NousResearch/Hermes-2-Theta-Llama-3-70B" = 0.3125
"google/gemma-3-27b-it" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-70B-Instruct" = 0.125
"mistral/mistral-small-2501" = 0.625
"sagemaker/01-ai/Yi-1.5-34B-Chat" = 0.6875
"alibaba/qwen-turbo-2024-11-01" = 0.375
"anthropic/claude-opus-4-20250514" = 1.0
"openai/gpt-4.1-2025-04-14" = 1.0
"openai/gpt-4o-2024-05-13" = 0.625
"google/gemini-1.5-flash-8b-001" = 0.0
"openai/gpt-4-1106-preview" = 0.3125
"openai/o1-mini-2024-09-12" = 0.875
"google/gemini-1.5-pro-002" = 1.0
"openai/o1-preview-2024-09-12" = 1.0
"google/gemini-1.5-flash-002" = 0.875
"mistral/open-mixtral-8x7b" = 0.25
"google/gemini-2.5-flash-preview-05-20" = 0.0
"anthropic/claude-2.0" = 0.0625
"fireworks/accounts/fireworks/models/deepseek-r1-0528" = 1.0
"sagemaker/mistralai/Mistral-7B-Instruct-v0.3" = 0.125
"sagemaker/microsoft/phi-4" = 0.6875
"openai/gpt-3.5-turbo-0125" = 0.3125
"alibaba/qwen-plus-2025-01-25" = 0.75
"google/gemini-2.0-flash-thinking-exp-01-21" = 1.0
"mistral/open-mixtral-8x22b" = 0.1875
"google/gemini-1.0-pro-001" = 0.125
"together/deepseek-ai/deepseek-r1-distill-qwen-14b" = 1.0
"together/microsoft/WizardLM-2-8x22B" = 0.5625
"alibaba/qwq-plus" = 1.0
"mistral/ministral-8b-2410" = 0.0625
"together/deepseek-ai/DeepSeek-V3" = 1.0
"together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" = 1.0
"sagemaker/01-ai/Yi-34B-Chat" = 0.3125
"sagemaker/Qwen/Qwen1.5-72B-Chat" = 0.125
"together/deepseek-ai/deepseek-r1-distill-llama-70b" = 0.75
"anthropic/claude-3-5-sonnet-20241022" = 0.8125
"alibaba/qwen-max-2025-01-25" = 1.0
"mistral/mistral-large-2407" = 0.25
"google/gemini-2.0-flash-001" = 1.0
"mistral/mistral-large-2411" = 0.625
"together/databricks/dbrx-instruct" = 0.0
"sagemaker/google/gemma-2-27b-it" = 0.0625
"openai/gpt-4o-mini-2024-07-18" = 0.0625
"sagemaker/google/gemma-2-9b-it" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct" = 0.4375
"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct" = 0.5625
"mistral/mistral-small-2503" = 0.75
"google/gemini-2.0-pro-exp-02-05" = 1.0
"google/gemini-2.5-pro-exp-03-25" = 1.0
"sagemaker/microsoft/Phi-3-medium-128k-instruct" = 0.125
"together/meta-llama/Llama-4-Scout-17B-16E-Instruct" = 1.0
"sagemaker/meta-llama/Meta-Llama-3-8B-Instruct" = 0.1875
"google/gemini-1.5-flash-001" = 0.125
"mistral/mistral-large-2402" = 0.0
"openai/gpt-4.1-nano-2025-04-14" = 0.875
"openai/gpt-4o-2024-11-20" = 0.75
"mistral/mistral-medium-2505" = 1.0
"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct" = 0.75
"openai/gpt-4-0125-preview" = 0.5
"fireworks/accounts/fireworks/models/deepseek-r1" = 1.0
"openai/gpt-4.5-preview-2025-02-27" = 1.0
"mistral/ministral-3b-2410" = 0.125
"sagemaker/PRIME-RL/Eurus-2-7B-PRIME" = 0.5625
"google/gemini-1.5-pro-001" = 0.1875
"openai/gpt-4o-2024-08-06" = 0.3125
"anthropic/claude-3-opus-20240229" = 0.5
"grok/grok-2-1212" = 0.9375
"sagemaker/meta-llama/Llama-2-70b-chat-hf" = 0.0
"fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct" = 0.25
